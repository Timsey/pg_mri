{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import random\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.policy_model.policy_model_utils import (load_policy_model, get_policy_probs, create_data_range_dict,\n",
    "                                                 compute_next_step_reconstruction)\n",
    "from src.reconstruction_model.reconstruction_model_utils import load_recon_model\n",
    "from src.helpers.data_loading import create_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_policy(args):   \n",
    "    # Reconstruction model\n",
    "    recon_args, recon_model = load_recon_model(args)\n",
    "\n",
    "    # Policy model\n",
    "    model, policy_args = load_policy_model(args.policy_model_checkpoint)\n",
    "    assert recon_args.resolution == policy_args.resolution == args.resolution\n",
    "    assert args.accelerations == policy_args.accelerations\n",
    "    assert args.reciprocals_in_center == policy_args.reciprocals_in_center\n",
    "    \n",
    "    args.center_fractions = policy_args.center_fractions\n",
    "    args.dataset = policy_args.dataset\n",
    "\n",
    "    loader = create_data_loader(args, 'test')\n",
    "    data_range_dict = create_data_range_dict(args, loader)\n",
    "    next_rows_dict = {}  # for average policy visualisation\n",
    "    return_this = False  # for single image visualisation\n",
    "    with torch.no_grad():\n",
    "        for it, data in enumerate(loader):\n",
    "            if args.single_image:\n",
    "                if args.image_idx >= it * args.val_batch_size and args.image_idx < (it + 1) * args.val_batch_size:\n",
    "                    ind = args.image_idx - it * args.val_batch_size\n",
    "                    return_this = True\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "            kspace, masked_kspace, mask, zf, gt, gt_mean, gt_std, fname, _ = data\n",
    "            # shape after unsqueeze = batch x channel x columns x rows x complex\n",
    "            kspace = kspace.unsqueeze(1).to(args.device)\n",
    "            masked_kspace = masked_kspace.unsqueeze(1).to(args.device)\n",
    "            mask = mask.unsqueeze(1).to(args.device)\n",
    "            # shape after unsqueeze = batch x channel x columns x rows\n",
    "            zf = zf.unsqueeze(1).to(args.device)\n",
    "            gt = gt.unsqueeze(1).to(args.device)\n",
    "            gt_mean = gt_mean.unsqueeze(1).unsqueeze(2).unsqueeze(3).to(args.device)\n",
    "            gt_std = gt_std.unsqueeze(1).unsqueeze(2).unsqueeze(3).to(args.device)\n",
    "            unnorm_gt = gt * gt_std + gt_mean\n",
    "            data_range = torch.stack([data_range_dict[vol] for vol in fname])\n",
    "            # Base reconstruction model forward pass\n",
    "            recons = recon_model(zf)\n",
    "            \n",
    "            for step in range(policy_args.acquisition_steps):\n",
    "                policy, probs = get_policy_probs(model, recons, mask)\n",
    "                if step == 0:\n",
    "                    actions = torch.multinomial(probs.squeeze(1), 1, replacement=True)  # single trajectory\n",
    "                else:\n",
    "                    actions = policy.sample()\n",
    "\n",
    "                mask, masked_kspace, zf, recons = compute_next_step_reconstruction(recon_model, kspace,\n",
    "                                                                                   masked_kspace, mask, actions)\n",
    "\n",
    "                if not step + 1 in next_rows_dict:\n",
    "                    next_rows_dict[step + 1] = actions.squeeze(-1).to('cpu')\n",
    "                else:\n",
    "                    next_rows_dict[step + 1] = np.concatenate((next_rows_dict[step + 1], \n",
    "                                                               actions.squeeze(-1).to('cpu').numpy()))\n",
    "                    \n",
    "            if return_this:              \n",
    "                return (gt[ind:ind+1, :, :, :].cpu(), \n",
    "                        recons[ind:ind+1, :, :, :].cpu(), \n",
    "                        mask[ind:ind+1, :, :, :, 0].cpu())\n",
    "\n",
    "        return next_rows_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_policies(base_args, row_dict, runs):\n",
    "    # Assumes four entries in row_dict to plot \n",
    "    assert len(row_dict) == len(runs) == 4\n",
    "    sns.set_style('dark')\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 2, sharey=True, sharex=True, figsize=(18, 8))\n",
    "\n",
    "    res = base_args.resolution\n",
    "    for run in runs:\n",
    "        rows = row_dict[run]\n",
    "        accel = 8\n",
    "        steps = len(rows)\n",
    "        \n",
    "        loc = 1\n",
    "        if 'nongreedy' in run or 'gamma' in run:\n",
    "            loc += 1\n",
    "        if 'long' in run:\n",
    "            accel = 32\n",
    "            loc += 2\n",
    "        \n",
    "        plt.subplot(2, 2, loc)\n",
    "        if loc == 1:\n",
    "            plt.title('Greedy', fontsize=18)\n",
    "            plt.ylabel('column', fontsize=15)\n",
    "        elif loc == 2:\n",
    "            if 'nongreedy' in run:\n",
    "                plt.title('NGreedy', fontsize=18)\n",
    "            elif 'gamma' in run:\n",
    "                plt.title('Î³ = 0.9', fontsize=18)\n",
    "            plt.yticks([], [])\n",
    "            plt.yticks([], [])\n",
    "        elif loc == 3:\n",
    "            plt.xlabel('acquisition step', fontsize=15)\n",
    "            plt.ylabel('column', fontsize=15)  \n",
    "        elif loc == 4:\n",
    "            plt.xlabel('acquisition step', fontsize=15)\n",
    "            plt.yticks([], [])\n",
    "        \n",
    "        img = np.zeros((res, steps + 1))\n",
    "        for step, row in rows.items():\n",
    "            for r in row:\n",
    "                img[r, step:] += 1\n",
    "        img /= len(rows[1])\n",
    "        img[int(res // 2 * (1 - 1/accel)):int(res // 2 * (1 + 1/accel)), :] = 1\n",
    "        im = plt.imshow(img, vmin=0, vmax=1, cmap='gist_gray', aspect='auto')\n",
    "        if loc == 4:\n",
    "            cbim = im\n",
    "            \n",
    "    fig.subplots_adjust(right=0.95)\n",
    "    cbar_ax = fig.add_axes([0.97, 0.14, 0.017, 0.7])\n",
    "    fig.colorbar(cbim, cax=cbar_ax)\n",
    "    fig.subplots_adjust(wspace=0.05, hspace=0.18)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_grid(base_args, image_dict, runs):\n",
    "    # Plot the image grid in the order given in 'runs' (plot from top to bottom)\n",
    "    assert len(image_dict) == len(runs)\n",
    "    \n",
    "    import torchvision\n",
    "    grid = []    \n",
    "    fig = plt.figure(figsize=(10, len(image_dict) * 2.5))\n",
    "    for run in runs:\n",
    "        gt, recon, mask = image_dict[run]\n",
    "        mask = mask.expand(-1, -1, mask.shape[-1], -1)\n",
    "        grid_row = torch.cat((mask, recon, gt, torch.abs(recon - gt)), dim=0)\n",
    "        grid.append(grid_row)\n",
    "        \n",
    "    grid = torch.cat(grid, dim=0)\n",
    "    grid_img = torchvision.utils.make_grid(grid, nrow=4, normalize=True, scale_each=True, pad_value=1)\n",
    "    plt.imshow(grid_img.permute(1,2,0), cmap='gist_gray', aspect='auto')\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    def __init__(self, dataset, recon_model_checkpoint, data_path):\n",
    "        self.seed = 0\n",
    "        self.device = 'cuda'\n",
    "        self.num_workers = 8\n",
    "        self.acquisition = None\n",
    "        self.reciprocals_in_center = [1]\n",
    "        self.recon_model_checkpoint = pathlib.Path(recon_model_checkpoint)\n",
    "        self.data_path = pathlib.Path(data_path)\n",
    "        \n",
    "        if dataset.lower() == 'knee':\n",
    "            self.center_volume = True\n",
    "            self.sample_rate = 0.5\n",
    "            self.val_batch_size = 512\n",
    "            self.resolution = 128\n",
    "        elif dataset.lower() == 'brain':\n",
    "            self.center_volume = False\n",
    "            self.sample_rate = 0.2\n",
    "            self.val_batch_size = 128\n",
    "            self.resolution = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN VALUES TO SET ###\n",
    "\n",
    "# Which dataset\n",
    "dataset = 'Knee'\n",
    "# dataset = 'Brain'\n",
    "\n",
    "# Which runs\n",
    "runs = ['base_greedy']\n",
    "# runs = ['base_greedy', 'base_nongreedy', 'long_greedy', 'long_nongreedy']\n",
    "# runs = ['base_greedy', 'base_gamma09', 'long_greedy', 'long_gamma09']\n",
    "\n",
    "# Visualise average policy\n",
    "average_policy = False\n",
    "# Visualise MR images in grid (not performed if average_policy is True)\n",
    "single_image = True\n",
    "image_idx = 0  # Which slice to pick\n",
    "\n",
    "# Set base path for policy models. Entries in policy_model_checkpoints will be appended to this base path \n",
    "# to construct the full policy model path. Corresponds to exp_dir in train_policy.py, though it can be set\n",
    "# in any way that works out with the relative policy model paths (to be specified further below).\n",
    "base_policy_path = '<base_path_to_stored_models>'\n",
    "\n",
    "if dataset.lower() == 'knee':\n",
    "    # Set data path, recon model checkpoint, and policy model checkpoints\n",
    "    data_path = '<path_to_knee_data>'\n",
    "    recon_model_checkpoint = '<path_to_recon_model.pt>'\n",
    "    policy_model_checkpoints = {'base_greedy': '<relative_path_to_policy_model.pt_from_base_policy_path>',\n",
    "                                'long_greedy': '<relative_path_to_policy_model.pt_from_base_policy_path>', \n",
    "                                'base_nongreedy': '<relative_path_to_policy_model.pt_from_base_policy_path>',\n",
    "                                'long_nongreedy': '<relative_path_to_policy_model.pt_from_base_policy_path>',\n",
    "                                'base_gamma09': '<relative_path_to_policy_model.pt_from_base_policy_path>',\n",
    "                                'long_gamma09': '<relative_path_to_policy_model.pt_from_base_policy_path>'}\n",
    "    \n",
    "elif dataset.lower() == 'brain':\n",
    "    # Set data path, recon model checkpoint, and policy model checkpoints\n",
    "    data_path = '<path_to_brain_data>'\n",
    "    recon_model_checkpoint = '<path_to_recon_model.pt>'\n",
    "    policy_model_checkpoints = {'base_greedy': '<relative_path_to_policy_model.pt_from_base_policy_path>',\n",
    "                                'long_greedy': '<relative_path_to_policy_model.pt_from_base_policy_path>', \n",
    "                                'base_nongreedy': '<relative_path_to_policy_model.pt_from_base_policy_path>',\n",
    "                                'long_nongreedy': '<relative_path_to_policy_model.pt_from_base_policy_path>',\n",
    "                                'base_gamma09': '<relative_path_to_policy_model.pt_from_base_policy_path>',\n",
    "                                'long_gamma09': '<relative_path_to_policy_model.pt_from_base_policy_path>'}\n",
    "\n",
    "### END VALUES TO SET ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_args = Arguments(dataset, recon_model_checkpoint, data_path)\n",
    "row_dict = {}\n",
    "image_dict = {}\n",
    "\n",
    "for run in runs:\n",
    "    print(run)\n",
    "    # Skip runs for which no policy model is given\n",
    "    if policy_model_checkpoints[run] is None:\n",
    "        continue\n",
    "        \n",
    "    # Set policy model\n",
    "    base_args.policy_model_checkpoint = pathlib.Path(base_policy_path) / policy_model_checkpoints[run]\n",
    "    \n",
    "    # Set horizon parameters\n",
    "    if 'base' in run:\n",
    "        base_args.accelerations = [8]\n",
    "        base_args.acquisition_steps = 16\n",
    "    elif 'long' in run:\n",
    "        base_args.accelerations = [32]\n",
    "        base_args.acquisition_steps = 28\n",
    "    \n",
    "    # Do average policy computation\n",
    "    if average_policy:\n",
    "        base_args.single_image = False  # either, or\n",
    "        rows = run_policy(base_args)\n",
    "        row_dict[run] = rows\n",
    "        \n",
    "    # Or just grab a single image from the policy run\n",
    "    if single_image:\n",
    "        base_args.single_image = True\n",
    "        base_args.image_idx = image_idx\n",
    "        gt, recon, mask = run_policy(base_args)\n",
    "        image_dict[run] = (gt, recon, mask)\n",
    "    \n",
    "# Plot functions\n",
    "if average_policy:\n",
    "    plot_average_policies(base_args, row_dict, runs)\n",
    "if single_image:\n",
    "    plot_image_grid(base_args, image_dict, runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rim",
   "language": "python",
   "name": "rim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
