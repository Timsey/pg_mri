{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import pathlib\n",
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.policy_model.policy_model_utils import (load_policy_model, get_policy_probs, create_data_range_dict,\n",
    "                                                 compute_next_step_reconstruction, compute_scores)\n",
    "from src.reconstruction_model.reconstruction_model_utils import load_recon_model\n",
    "from src.helpers.data_loading import create_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, recon_model, model, loader, data_range_dict):\n",
    "    \"\"\"\n",
    "    Evaluates using SSIM of reconstruction over trajectory. Doesn't require computing targets!\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    rows_dict = defaultdict(list)\n",
    "    cond_ent_dict = defaultdict(float)\n",
    "    marg_prob_dict = defaultdict(float)\n",
    "    \n",
    "    tbs = 0  # data set size counter\n",
    "    with torch.no_grad():\n",
    "        for it, data in enumerate(loader):\n",
    "            kspace, masked_kspace, mask, zf, gt, gt_mean, gt_std, fname, _ = data\n",
    "            # shape after unsqueeze = batch x channel x columns x rows x complex\n",
    "            kspace = kspace.unsqueeze(1).to(args.device)\n",
    "            masked_kspace = masked_kspace.unsqueeze(1).to(args.device)\n",
    "            mask = mask.unsqueeze(1).to(args.device)\n",
    "            # shape after unsqueeze = batch x channel x columns x rows\n",
    "            zf = zf.unsqueeze(1).to(args.device)\n",
    "            gt = gt.unsqueeze(1).to(args.device)\n",
    "            gt_mean = gt_mean.unsqueeze(1).unsqueeze(2).unsqueeze(3).to(args.device)\n",
    "            gt_std = gt_std.unsqueeze(1).unsqueeze(2).unsqueeze(3).to(args.device)\n",
    "            unnorm_gt = gt * gt_std + gt_mean\n",
    "            data_range = torch.stack([data_range_dict[vol] for vol in fname])\n",
    "            tbs += mask.size(0)\n",
    "\n",
    "            # Base reconstruction model forward pass\n",
    "            recons = recon_model(zf)\n",
    "\n",
    "            for step in range(args.acquisition_steps):\n",
    "                policy, probs = get_policy_probs(model, recons, mask)\n",
    "                if step == 0:\n",
    "                    actions = torch.multinomial(probs.squeeze(1), args.num_test_trajectories, replacement=True)\n",
    "                else:\n",
    "                    actions = policy.sample()\n",
    "                    \n",
    "                # Store all trajectories per data point\n",
    "                rows_dict[step].extend(actions.cpu().numpy().tolist())\n",
    "                # ent over rows, average over trajs, sum over data points\n",
    "                cond_ent_dict[step] += ent(probs.cpu(), dim=-1).sum(dim=0).mean()\n",
    "                marg_prob_dict[step] += probs.cpu().mean(dim=1).sum(dim=0)\n",
    "                \n",
    "                # Samples trajectories in parallel\n",
    "                # For evaluation we can treat greedy and non-greedy the same: in both cases we just simulate\n",
    "                # num_test_trajectories acquisition trajectories in parallel for each slice in the batch, and store\n",
    "                # the average SSIM score every time step.\n",
    "                mask, masked_kspace, zf, recons = compute_next_step_reconstruction(recon_model, kspace,\n",
    "                                                                                   masked_kspace, mask, actions)\n",
    "\n",
    "    avg_cond_ent_dict = {step: sum_ent / tbs for step, sum_ent in cond_ent_dict.items()}\n",
    "    avg_marg_ent_dict = {step: ent(marg_prob / tbs, dim=0) for step, marg_prob in marg_prob_dict.items()}        \n",
    "    return rows_dict, avg_cond_ent_dict, avg_marg_ent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ckpt_from_id(run_id, base, entity, project):\n",
    "    run = api.run(f'{entity}/{project}/{run_id}')\n",
    "    args = run.config\n",
    "    ckpt = base / pathlib.Path(args['run_dir']).name / 'model.pt'\n",
    "    return ckpt\n",
    "\n",
    "def ent(probs, dim):\n",
    "    probs = probs + 1e-11\n",
    "    logprobs = torch.log(probs)\n",
    "    ent =  (-1 * probs * logprobs).sum(dim=dim)\n",
    "    return ent\n",
    "\n",
    "def save_results(res, save_name):\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(res, f)\n",
    "    return None\n",
    "        \n",
    "def load_results(save_name):\n",
    "    with open(save_name, 'rb') as f:\n",
    "        res = pickle.load(f)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    def __init__(self, accel, acq, force, res, batch_size, sample_rate, center_volume, recon_model_checkpoint, data_path, dataset):\n",
    "        self.accelerations = [accel]\n",
    "        self.center_fractions = [1 / accel]\n",
    "        self.acquisition_steps = acq\n",
    "        self.resolution = res\n",
    "        self.val_batch_size = batch_size\n",
    "        self.batches_step = 1\n",
    "        self.num_trajectories = 8\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        self.data_path = pathlib.Path(data_path)\n",
    "        self.recon_model_checkpoint = pathlib.Path(recon_model_checkpoint)\n",
    "        \n",
    "        self.sample_rate = sample_rate\n",
    "        self.acquisition = None\n",
    "        self.center_volume = center_volume\n",
    "        self.device = 'cuda'\n",
    "        self.num_workers = 4\n",
    "        \n",
    "        self.force = force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN VALUES TO SET ###\n",
    "\n",
    "dataset = 'knee'  # or 'brain'\n",
    "wandb_entity = 'WANDB_ENTITY NAME'\n",
    "\n",
    "wandb_knee_project = 'WANDB_KNEE_PROJECT_NAME'\n",
    "wandb_brain_project = 'WANDB_BRAIN_PROJECT_NAME'\n",
    "\n",
    "# Set base path for policy models. Corresponds to exp_dir in train_policy.py\n",
    "knee_base = '<path_to_knee_policy_model_base_dir>'\n",
    "brain_base = '<path_to_brain_policy_model_base_dir>'\n",
    "\n",
    "# Whether to overwrite SSIM values stored on drive if exist\n",
    "force = False\n",
    "\n",
    "if dataset == 'knee':\n",
    "    batch_size = 128\n",
    "    res = 128\n",
    "    sample_rate = 0.5\n",
    "    center_volume = True\n",
    "    data_path = '<path_to_knee_data>'\n",
    "    recon_model_checkpoint = '<path_to_knee_recon_model.pt>'\n",
    "    wandb_project = wandb_knee_project\n",
    "\n",
    "elif dataset == 'brain':\n",
    "    res = 256\n",
    "    sample_rate = 0.2\n",
    "    center_volume = False\n",
    "    batch_size = 32\n",
    "    data_path = '<path_to_brain_data>'\n",
    "    recon_model_checkpoint = '<path_to_brain_recon_model.pt>'\n",
    "    wandb_project = wandb_brain_project\n",
    "\n",
    "### END VALUES TO SET ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a dictionary of run names, dirs and ids, based on the Wandb API.    \n",
    "\n",
    "run_id_dict = {\"16-32\": defaultdict(dict),\n",
    "               \"4-32\": defaultdict(dict)}\n",
    "\n",
    "runs = api.runs(f\"{wandb_entity}/{wandb_project}\", {\"config.sample_rate\": sample_rate})\n",
    "for run in runs:\n",
    "    if not run.state == 'finished':\n",
    "        continue\n",
    "    \n",
    "    name = run.name\n",
    "    args = run.config\n",
    "    if args['dataset'].lower() != dataset.lower():\n",
    "        continue  # Skip models not on given dataset\n",
    "        \n",
    "    ### YOUR FILTERS HERE ###\n",
    "\n",
    "    if args['model_type'] == 'greedy':\n",
    "        key = 'greedy'\n",
    "    elif args['gamma'] == 1:\n",
    "        key = 'nongreedy'\n",
    "    else:\n",
    "        key = args['gamma']\n",
    "                \n",
    "    run_dir = args['run_dir'].split('/')[-1]\n",
    "    \n",
    "    if args['accelerations'] == [8]:\n",
    "        run_id_dict[\"16-32\"][key][name] = {'id': run.id, 'dir': run_dir}\n",
    "    elif args['accelerations'] == [32]:\n",
    "        run_id_dict[\"4-32\"][key][name] = {'id': run.id, 'dir': run_dir}\n",
    "            \n",
    "pprint(run_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows_dict = defaultdict(lambda: defaultdict(dict))\n",
    "all_cond_ent_dict = defaultdict(lambda: defaultdict(dict))\n",
    "all_marg_ent_dict = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "# Load recon model\n",
    "args = Arguments(2, 2, force, res, batch_size, sample_rate, center_volume, recon_model_checkpoint, data_path, dataset)\n",
    "recon_args, recon_model = load_recon_model(args)\n",
    "\n",
    "for horizon, mode_dict in run_id_dict.items():            \n",
    "    if horizon == '16-32':\n",
    "        accel = 8\n",
    "        acq = 16\n",
    "    elif horizon == '4-32':\n",
    "        accel = 32\n",
    "        acq = 28\n",
    "    else:\n",
    "        print(horizon)\n",
    "        raise ValueError()\n",
    "                \n",
    "    # Load data for this horizon\n",
    "    args = Arguments(accel, acq, force, res, batch_size, sample_rate, center_volume, recon_model_checkpoint, data_path, dataset)\n",
    "    loader = create_data_loader(args, 'test')\n",
    "\n",
    "    for mode, runs in mode_dict.items(): \n",
    "        if dataset == 'knee':\n",
    "            base = pathlib.Path(knee_base)\n",
    "        elif dataset == 'brain':\n",
    "            base = pathlib.Path(brain_base)\n",
    "            \n",
    "        for name, run_dict in runs.items():\n",
    "            run_id = run_dict['id']\n",
    "            run_dir = run_dict['dir']\n",
    "            print(horizon, mode, name, run_id)\n",
    "            # Actually have checkpoint in run_dir already\n",
    "            ckpt = get_ckpt_from_id(run_id, base, wandb_entity, wandb_project)\n",
    "            \n",
    "            try:\n",
    "                model, policy_args = load_policy_model(pathlib.Path(ckpt))\n",
    "            except FileNotFoundError:\n",
    "                print(f'File not found: {args.policy_model_checkpoint}')\n",
    "                continue\n",
    "\n",
    "            policy_args.num_test_trajectories = args.num_trajectories\n",
    "            \n",
    "            row_save_name = ckpt.parent / f'rows_t{args.num_trajectories}.pkl'\n",
    "            cond_ent_save_name = ckpt.parent / f'ent_t{args.num_trajectories}.pkl'\n",
    "            marg_ent_save_name = ckpt.parent / f'ment_t{args.num_trajectories}.pkl'\n",
    "    \n",
    "            if row_save_name.exists() and cond_ent_save_name.exists() and marg_ent_save_name.exists() and not args.force:\n",
    "                print(f'Results already stored in: \\n   {row_save_name.parent}')               \n",
    "                rows = load_results(row_save_name)\n",
    "                cents = load_results(cond_ent_save_name)\n",
    "                ments = load_results(marg_ent_save_name)\n",
    "            else:\n",
    "                data_range_dict = create_data_range_dict(args, loader)\n",
    "                rows, cents, ments = evaluate(policy_args, recon_model, model, loader, data_range_dict)\n",
    "\n",
    "            save_results(rows, row_save_name)\n",
    "            save_results(cents, cond_ent_save_name)\n",
    "            save_results(ments, marg_ent_save_name)\n",
    "            \n",
    "            all_rows_dict[horizon][mode][name] = rows\n",
    "            all_cond_ent_dict[horizon][mode][name] = cents\n",
    "            all_marg_ent_dict[horizon][mode][name] = ments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mutual information\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "cdict = {'greedy': 'tab:blue', 'non-greedy': 'tab:cyan', '0.9': 'tab:orange'}\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for horizon, hor_dict in sorted(all_cond_ent_dict.items()):\n",
    "    if horizon == '16-32':\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.ylabel('mutual information (nats)', fontsize=15)\n",
    "        plt.xlabel('acquisition step', fontsize=15)\n",
    "        plt.ylim(0, 2.6)\n",
    "        plt.title('base horizon', fontsize=18)\n",
    "    else:\n",
    "        continue\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.xlabel('acquisition step', fontsize=15)\n",
    "        plt.ylim(0, 2.6)\n",
    "        plt.title('long horizon', fontsize=18)\n",
    "        \n",
    "    for mode, mode_dict in hor_dict.items():\n",
    "        if mode == 'greedy':\n",
    "            label = 'greedy'\n",
    "        if mode == 'nongreedy':\n",
    "            label = 'non-greedy'\n",
    "        if mode == 0.9:\n",
    "            label = '0.9'\n",
    "            \n",
    "        cent_list = []\n",
    "        ment_list = []\n",
    "        for name, ents in mode_dict.items():\n",
    "            cent_list.append([val for step, val in ents.items()])\n",
    "            ment_list.append([val for step, val in all_marg_ent_dict[horizon][mode][name].items()])\n",
    "        \n",
    "        cent_arr = np.array(cent_list)\n",
    "        ment_arr = np.array(ment_list)\n",
    "        \n",
    "        minf = ment_arr - cent_arr\n",
    "        \n",
    "        avg_minf = np.mean(minf, axis=0)\n",
    "        std_minf = np.std(minf, axis=0, ddof=1)\n",
    "\n",
    "        steps = list(range(1, len(avg_minf) + 1))\n",
    "        plt.plot(steps, avg_minf, label=label, color=cdict[label])\n",
    "        plt.fill_between(steps, avg_minf-std_minf, avg_minf+std_minf, alpha=0.3, color=cdict[label])\n",
    "    \n",
    "    plt.legend(loc='upper left')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot conditional and marginal entropy\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "cdict = {'greedy': 'tab:blue', 'non-greedy': 'tab:cyan', '0.9': 'tab:orange'}\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for horizon, hor_dict in sorted(all_cond_ent_dict.items()):\n",
    "    if horizon == '16-32':\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.ylabel('entropy (nats)', fontsize=15)\n",
    "        plt.xlabel('acquisition step', fontsize=15)\n",
    "        plt.ylim(0, 4)\n",
    "        plt.title('long horizon', fontsize=18)\n",
    "    else:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.xlabel('acquisition step', fontsize=15)\n",
    "        plt.ylim(0, 4)\n",
    "        plt.title('long horizon', fontsize=18)\n",
    "        \n",
    "    for mode, mode_dict in hor_dict.items():\n",
    "        if mode == 'greedy':\n",
    "            label = 'greedy'\n",
    "        if mode == 'nongreedy':\n",
    "            label = 'non-greedy'\n",
    "        if mode == 0.9:\n",
    "            label = '0.9'\n",
    "            \n",
    "        cent_list = []\n",
    "        ment_list = []\n",
    "        for name, ents in mode_dict.items():\n",
    "            cent_list.append([val for step, val in ents.items()])\n",
    "            ment_list.append([val for step, val in all_marg_ent_dict[horizon][mode][name].items()])\n",
    "        \n",
    "        cent_arr = np.array(cent_list)\n",
    "        ment_arr = np.array(ment_list)\n",
    "        \n",
    "        avg_cent = np.mean(cent_arr, axis=0)\n",
    "        std_cent = np.std(cent_arr, axis=0, ddof=1)\n",
    "        \n",
    "        avg_ment = np.mean(ment_arr, axis=0)\n",
    "        std_ment = np.std(ment_arr, axis=0, ddof=1)\n",
    "\n",
    "        steps = list(range(1, len(avg_ment) + 1))\n",
    "        plt.plot(steps, avg_ment, '--', label=f'{label} marg ent', color=cdict[label])\n",
    "        plt.fill_between(steps, avg_ment-std_ment, avg_ment+std_ment, alpha=0.3, color=cdict[label])\n",
    "        \n",
    "        plt.plot(steps, avg_cent, label=f'{label} cond ent', color=cdict[label])\n",
    "        plt.fill_between(steps, avg_cent-std_cent, avg_cent+std_cent, alpha=0.3, color=cdict[label])\n",
    "    \n",
    "    plt.legend(loc='upper left')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rim",
   "language": "python",
   "name": "rim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
