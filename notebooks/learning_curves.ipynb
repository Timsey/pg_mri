{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curves\n",
    "This notebook creates the learning curve plots seen in the paper. It requires stored wandb policy model runs. Set the below variables to the correct wandb entity and project. Using the wandb API we will create a dictionary that stores the runs we want to do computations for. Make sure to check that this dictionary contains the correct runs, and write the correct filters if this is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'knee'  # or 'brain'\n",
    "wandb_entity = 'WANDB_ENTITY NAME'\n",
    "wandb_project = 'WANDB_PROJECT_NAME'\n",
    "\n",
    "# Partitions to plot learning curves for\n",
    "partitions = ['train', 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a dictionary of run names, dirs and ids, based on the Wandb API.\n",
    "\n",
    "if dataset.lower() == 'knee':\n",
    "    sample_rate = 0.5\n",
    "if dataset.lower() == 'brain':\n",
    "    sample_rate = 0.2\n",
    "\n",
    "run_id_dict = {\"16-32\": defaultdict(dict),\n",
    "               \"4-32\": defaultdict(dict)}\n",
    "\n",
    "runs = api.runs(f\"{wandb_entity}/{wandb_project}\", {\"config.sample_rate\": sample_rate})\n",
    "for run in runs:\n",
    "    if not run.state == 'finished':\n",
    "        continue\n",
    "    \n",
    "    name = run.name\n",
    "    args = run.config\n",
    "    \n",
    "    if args['dataset'].lower() != dataset.lower():\n",
    "        continue  # Skip models not on given dataset\n",
    "        \n",
    "    ### YOUR FILTERS HERE ###\n",
    "\n",
    "    if args['model_type'] == 'greedy':\n",
    "        key = 'greedy'\n",
    "    elif args['gamma'] == 1:\n",
    "        key = 'nongreedy'\n",
    "    else:\n",
    "        key = args['gamma']\n",
    "                \n",
    "    run_dir = args['run_dir'].split('/')[-1]\n",
    "    \n",
    "    if args['accelerations'] == [8]:\n",
    "        run_id_dict[\"16-32\"][key][name] = {'id': run.id, 'dir': run_dir}\n",
    "    elif args['accelerations'] == [32]:\n",
    "        run_id_dict[\"4-32\"][key][name] = {'id': run.id, 'dir': run_dir}\n",
    "            \n",
    "pprint(run_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_curve(runs, entity, project, final_step, partition):\n",
    "    curves = []\n",
    "    for run_name, run_data in runs.items():\n",
    "        run_id = run_data['id']\n",
    "        run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "        try:\n",
    "            vals = run.history()[f'{partition}_ssims.{final_step}'][:50]\n",
    "            curves.append(np.array(vals))\n",
    "        except KeyError:\n",
    "            print(partition, run_name)\n",
    "            continue\n",
    "    \n",
    "    curves = np.stack(curves)    \n",
    "    return np.mean(curves, axis=0), np.std(curves, axis=0, ddof=1)\n",
    "\n",
    "def get_curve_statistics(run_dict, horizon, partition, dataset, entity, wandb_project):\n",
    "    if dataset == 'Knee':\n",
    "        greedy_runs = run_dict[hor]['greedy']\n",
    "        ngreedy_runs = run_dict[hor]['nongreedy']\n",
    "        g09_runs = run_dict[hor][0.9]\n",
    "\n",
    "        gmean, gstd = get_learning_curve(greedy_runs, entity, wandb_project, final_step, partition)\n",
    "        ngmean, ngstd = get_learning_curve(ngreedy_runs, entity, wandb_project, final_step, partition)\n",
    "        g09mean, g09std = get_learning_curve(g09_runs, entity, wandb_project, final_step, partition)\n",
    "\n",
    "        return ((gmean, gstd), (ngmean, ngstd), (g09mean, g09std))\n",
    "\n",
    "    if dataset == 'Brain':\n",
    "        greedy_runs = run_dict[hor]['greedy']\n",
    "        ngreedy_runs = run_dict[hor]['nongreedy']\n",
    "        g09_runs = run_dict[hor][0.9]\n",
    "    \n",
    "        gmean, gstd = get_learning_curve(greedy_runs, entity, wandb_project, final_step, partition)\n",
    "        ngmean, ngstd = get_learning_curve(ngreedy_runs, entity, wandb_project, final_step, partition)\n",
    "        g09mean, g09std = get_learning_curve(g09_runs, entity, wandb_project, final_step, partition)\n",
    "\n",
    "        return ((gmean, gstd), (ngmean, ngstd), (g09mean, g09std))\n",
    "\n",
    "def plot_learning_curves(vals, labels, cdict, final_step, num, partition, partitions, dataset):\n",
    "    if partition == 'train':\n",
    "        num += 2\n",
    "        \n",
    "    plt.subplot(len(partitions), 2, num + 1)\n",
    "    \n",
    "    # Val base\n",
    "    if num == 0:\n",
    "        if dataset == 'Knee':\n",
    "            ylims = (.7135, 0.7175)\n",
    "        else:\n",
    "            ylims = (.9135, 0.9152)\n",
    "            plt.xlabel('epoch', fontsize=15)\n",
    "        plt.title('Base horizon', fontsize=18)\n",
    "        plt.ylabel('val SSIM', fontsize=15)\n",
    "    # Val long\n",
    "    elif num == 1:\n",
    "        if dataset == 'Knee':\n",
    "            ylims = (.736, 0.742)  \n",
    "        else:\n",
    "            ylims = (.865, 0.905)\n",
    "            plt.xlabel('epoch', fontsize=15)\n",
    "        plt.title('Long horizon', fontsize=18)\n",
    "    # Train base\n",
    "    elif num == 2:\n",
    "        if dataset == 'Knee':\n",
    "            ylims = (.722, 0.7325)  \n",
    "        plt.xlabel('epoch', fontsize=15)\n",
    "        plt.ylabel('train SSIM', fontsize=15)\n",
    "    # Train long\n",
    "    elif num == 3:\n",
    "        if dataset == 'Knee':\n",
    "            ylims = (.739, 0.751)  \n",
    "        plt.xlabel('epoch', fontsize=15)\n",
    "\n",
    "    t = list(range(vals[0][0].shape[-1]))\n",
    "    for i, val in enumerate(vals):\n",
    "        label = labels[i]\n",
    "        means = val[0]\n",
    "        stds = val[1]\n",
    "        plt.plot(t, means, label=f'{label}', c=cdict[label])\n",
    "        plt.fill_between(t, means-stds, means+stds, alpha=.3, color=cdict[label])\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.ylim(*ylims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdict = {'Greedy': 'tab:blue', 'NGreedy': 'tab:cyan', 'γ = 0.9': 'tab:orange'}\n",
    "labels = ['Greedy', 'NGreedy', 'γ = 0.9']\n",
    "plt.figure(figsize=(18, 3.5 * len(partitions)))\n",
    "for i, horizon in enumerate(['base', 'long']):\n",
    "    if horizon == 'base':\n",
    "        hor = '16-32'\n",
    "        final_step = 16\n",
    "    elif horizon == 'long':\n",
    "        hor = '4-32'\n",
    "        final_step = 28\n",
    "    else:\n",
    "        raise ValueError('Unknown value for horizon.')\n",
    "    \n",
    "    for partition in partitions:\n",
    "        vals = get_curve_statistics(run_id_dict, horizon, partition, dataset, wandb_entity, wandb_project)    \n",
    "        plot_learning_curves(vals, labels, cdict, final_step, i, partition, partitions, dataset)\n",
    "\n",
    "plt.suptitle(f'{dataset} learning curves', fontsize=21)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rim",
   "language": "python",
   "name": "rim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
